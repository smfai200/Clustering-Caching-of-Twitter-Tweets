{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division \n",
    "import os \n",
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re #regular expression\n",
    "from textblob import TextBlob\n",
    "import string\n",
    "import numpy as np\n",
    "from Cleaner import api as p\n",
    "import warnings \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may have problems with preprocessor\n",
    "# to Install\n",
    "# pip install git+git://github.com/s/preprocessor.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = os.path.realpath('../data') \n",
    "with pd.HDFStore(os.path.join(datadir, 'results.h5')) as store: \n",
    "    tweets = store.results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>text</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>mb_cluster</th>\n",
       "      <th>db_cluster</th>\n",
       "      <th>cluster</th>\n",
       "      <th>hdb_cluster</th>\n",
       "      <th>final_cluster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>377652254096228352</td>\n",
       "      <td>37.446100</td>\n",
       "      <td>-121.883557</td>\n",
       "      <td>@Tanner_Cortez hey checkout the website: http:...</td>\n",
       "      <td>2013-09-11 04:38:08</td>\n",
       "      <td>224874450</td>\n",
       "      <td>44</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377652262325456897</td>\n",
       "      <td>37.356131</td>\n",
       "      <td>-121.842867</td>\n",
       "      <td>i laugh a lot with that line</td>\n",
       "      <td>2013-09-11 04:38:10</td>\n",
       "      <td>54351774</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377652264682655744</td>\n",
       "      <td>37.364664</td>\n",
       "      <td>-122.009629</td>\n",
       "      <td>sons of anarchy is back on woop woop</td>\n",
       "      <td>2013-09-11 04:38:11</td>\n",
       "      <td>343219606</td>\n",
       "      <td>34</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377652271116722176</td>\n",
       "      <td>37.382600</td>\n",
       "      <td>-121.995000</td>\n",
       "      <td>Drinking a Fresh Squeezed IPA by @deschutesbee...</td>\n",
       "      <td>2013-09-11 04:38:12</td>\n",
       "      <td>1569395935</td>\n",
       "      <td>34</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>377652275147444224</td>\n",
       "      <td>37.756149</td>\n",
       "      <td>-122.152813</td>\n",
       "      <td>I have 8 am classes this quarter ... I need to...</td>\n",
       "      <td>2013-09-11 04:38:13</td>\n",
       "      <td>399164195</td>\n",
       "      <td>31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          lat         lng  \\\n",
       "id                                          \n",
       "377652254096228352  37.446100 -121.883557   \n",
       "377652262325456897  37.356131 -121.842867   \n",
       "377652264682655744  37.364664 -122.009629   \n",
       "377652271116722176  37.382600 -121.995000   \n",
       "377652275147444224  37.756149 -122.152813   \n",
       "\n",
       "                                                                 text  \\\n",
       "id                                                                      \n",
       "377652254096228352  @Tanner_Cortez hey checkout the website: http:...   \n",
       "377652262325456897                       i laugh a lot with that line   \n",
       "377652264682655744               sons of anarchy is back on woop woop   \n",
       "377652271116722176  Drinking a Fresh Squeezed IPA by @deschutesbee...   \n",
       "377652275147444224  I have 8 am classes this quarter ... I need to...   \n",
       "\n",
       "                             timeStamp     user_id  mb_cluster  db_cluster  \\\n",
       "id                                                                           \n",
       "377652254096228352 2013-09-11 04:38:08   224874450          44        -1.0   \n",
       "377652262325456897 2013-09-11 04:38:10    54351774           1        -1.0   \n",
       "377652264682655744 2013-09-11 04:38:11   343219606          34        -1.0   \n",
       "377652271116722176 2013-09-11 04:38:12  1569395935          34        -1.0   \n",
       "377652275147444224 2013-09-11 04:38:13   399164195          31         0.0   \n",
       "\n",
       "                    cluster  hdb_cluster  final_cluster  \n",
       "id                                                       \n",
       "377652254096228352      NaN         -1.0            NaN  \n",
       "377652262325456897      NaN         -1.0            NaN  \n",
       "377652264682655744      NaN         -1.0            NaN  \n",
       "377652271116722176      NaN         -1.0            NaN  \n",
       "377652275147444224     31.0          0.0           31.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lng', 'text', 'timeStamp', 'user_id', 'mb_cluster',\n",
       "       'db_cluster', 'cluster', 'hdb_cluster', 'final_cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handle Emoticons and Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HappyEmoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Emoji patterns\n",
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine sad and happy emoticons\n",
    "emoticons = emoticons_happy.union(emoticons_sad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(tweet):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(tweet)\n",
    "    tweet = re.sub(r':', '', tweet)\n",
    "    tweet = re.sub(r'‚Äö√Ñ¬∂', '', tweet)\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet)\n",
    "    tweet = emoji_pattern.sub(r'', tweet)\n",
    "    filtered_tweet = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_tweet = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words and w not in emoticons and w not in string.punctuation:\n",
    "            filtered_tweet.append(w)\n",
    "    return ' '.join(filtered_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Successful\n",
      "Sample:  ['hey checkout website', 'laugh lot line', 'sons anarchy back woop woop', \"Drinking Fresh Squeezed IPA St. John 's Bar amp Grill ‚Äî\", 'I classes quarter ... I need get sleep thing together']\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = []\n",
    "for singletext in tweets[\"text\"]:\n",
    "    clean_text = p.clean(singletext)\n",
    "    filtered_tweet=clean_tweets(clean_text)\n",
    "    cleaned_text.append(filtered_tweet)\n",
    "\n",
    "print(\"Cleaning Successful\")\n",
    "print(\"Sample: \", cleaned_text[:5])\n",
    "# p.clean('Preprocessor is #awesome üëç https://github.com/s/preprocessor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"Cleaned_Initial\"] = cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary and Word Counts for IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stop_set = set(stopwords.words('english'))\n",
    "frozenset(stop_set)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = tweets[\"Cleaned_Initial\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['separate_words'] = tweets.text.str.strip().str.split('[\\W_]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(docs,max_df=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_vector = cv.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab = {}\n",
    "for key,value in cv.vocabulary_.items():\n",
    "    if(len(key) < 4):\n",
    "        pass\n",
    "    else:\n",
    "        new_vocab[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = pd.DataFrame(list(new_vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>checkout</td>\n",
       "      <td>25290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>website</td>\n",
       "      <td>147619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>laugh</td>\n",
       "      <td>78212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>line</td>\n",
       "      <td>80123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>sons</td>\n",
       "      <td>126833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1\n",
       "0  checkout   25290\n",
       "1   website  147619\n",
       "2     laugh   78212\n",
       "3      line   80123\n",
       "4      sons  126833"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df.to_csv(\"../data/results/Vocab_Frame.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfTransformer to Compute Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    " \n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ca</td>\n",
       "      <td>3.994374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>like</td>\n",
       "      <td>4.102876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>lol</td>\n",
       "      <td>4.275962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>san</td>\n",
       "      <td>4.409975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>the</td>\n",
       "      <td>4.441400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>krustiee</td>\n",
       "      <td>13.909247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>krust</td>\n",
       "      <td>13.909247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>krusher</td>\n",
       "      <td>13.909247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>krys</td>\n",
       "      <td>13.909247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ÔæüÔæü</td>\n",
       "      <td>13.909247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179781 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          idf_weights\n",
       "ca           3.994374\n",
       "like         4.102876\n",
       "lol          4.275962\n",
       "san          4.409975\n",
       "the          4.441400\n",
       "...               ...\n",
       "krustiee    13.909247\n",
       "krust       13.909247\n",
       "krusher     13.909247\n",
       "krys        13.909247\n",
       "ÔæüÔæü          13.909247\n",
       "\n",
       "[179781 rows x 1 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print idf values\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"])\n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector=cv.transform(docs) \n",
    "# tf-idf scores\n",
    "tf_idf_vector=tfidf_transformer.transform(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_document_vector=tf_idf_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>checkout</td>\n",
       "      <td>0.692689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>website</td>\n",
       "      <td>0.584278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hey</td>\n",
       "      <td>0.422850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>seacliff</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>seabitches</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halfs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halftime</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halftimes</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>halfway</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ÔæüÔæü</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179781 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfidf\n",
       "checkout    0.692689\n",
       "website     0.584278\n",
       "hey         0.422850\n",
       "seacliff    0.000000\n",
       "seabitches  0.000000\n",
       "...              ...\n",
       "halfs       0.000000\n",
       "halftime    0.000000\n",
       "halftimes   0.000000\n",
       "halfway     0.000000\n",
       "ÔæüÔæü          0.000000\n",
       "\n",
       "[179781 rows x 1 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"])\n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/results/TFIDF_SparseMatrix.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lng', 'text', 'timeStamp', 'user_id', 'mb_cluster',\n",
       "       'db_cluster', 'cluster', 'hdb_cluster', 'final_cluster',\n",
       "       'Cleaned_Initial', 'separate_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\faizan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3326: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block4_values] [items->['text', 'Cleaned_Initial', 'separate_words']]\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "with pd.HDFStore(os.path.join(datadir, 'results.h5'), mode='w') as results: \n",
    "    results['results'] = tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
